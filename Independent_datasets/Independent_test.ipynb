{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'AA', u'Acetylation', u'CRISPRO_score',\n",
      "       u'CRISPRscan.score', u'Chari.rank', u'Chari.score', u'Chr', u'DSB_coor',\n",
      "       u'DeepCRISPR_score', u'DeepHF_score', u'Domain_pfam',\n",
      "       u'Essential_Zscore', u'FrameShift_FORECasT', u'FrameShift_IndelPhi',\n",
      "       u'FrameShift_Lindel', u'Helix', u'Index', u'LoF_com', u'LoF_ind',\n",
      "       u'LoF_pro', u'LoF_seq', u'PROVEAN_score', u'Phosphorylation',\n",
      "       u'SIFT_score', u'SSC_score', u'Score', u'Sheet', u'Symbol',\n",
      "       u'Unnamed: 0.1', u'Wang.score', u'WuCRISPR.score', u'dataset',\n",
      "       u'doench_score', u'loci_longseq', u'longseq100bp', u'sgRNASeq',\n",
      "       u'strand'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_csv('Testing_set2_results_new.csv')\n",
    "\n",
    "print df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanjana2014_GeCKOv2\n",
      "Evers2016-UMUC3\n",
      "Bertomeu2018-EKO-NALM6\n",
      "Schoonenberg2018-CRISPRO\n",
      "Evers2016-RT112\n"
     ]
    }
   ],
   "source": [
    "for data in list(set(df_all['dataset'])):\n",
    "    print data\n",
    "    df = df_all[df_all['dataset']==data]\n",
    "    df_data = df.loc[:,[u'AA', u'Acetylation', u'CRISPRO_score',\n",
    "       u'CRISPRscan.score', u'Chari.rank', u'Chari.score', u'Chr', u'DSB_coor',\n",
    "       u'DeepCRISPR_score', u'DeepHF_score', u'Domain_pfam',\n",
    "       u'Essential_Zscore', u'FrameShift_FORECasT', u'FrameShift_IndelPhi',\n",
    "       u'FrameShift_Lindel', u'Helix', u'Index', u'PROVEAN_score', u'Phosphorylation',\n",
    "       u'SIFT_score', u'SSC_score', u'Score', u'Sheet', u'Symbol',\n",
    "       u'Wang.score', u'WuCRISPR.score', u'dataset',\n",
    "       u'doench_score', u'loci_longseq', u'longseq100bp', u'sgRNASeq',\n",
    "       u'strand']]\n",
    "    \n",
    "    df_data.to_csv('Testing_'+data+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 183:1 194:1 201:1 214:1\\n0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 181:1 191:1 201:1 211:1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seqsToChariSvml(seqs):\n",
    "    \"\"\" partially copied from generateSVMFile.FASTA.py in the Chari et al source code\n",
    "    >>> seqsToChariSvml([\"CTTCTTCAAGGTAACTGCAGA\", \"CTTCTTCAAGGTAACTGGGGG\"])\n",
    "    '0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 183:1 194:1 201:1 214:1\\\\n0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 181:1 191:1 201:1 211:1'\n",
    "    \"\"\"\n",
    "    vecs = []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)==21)\n",
    "        vec = []\n",
    "        # end index\n",
    "        for pos in range(0, 21):\n",
    "            for nuclIdx, char in enumerate(\"GTCA\"):\n",
    "                val = int(seq[pos]==char)\n",
    "                if val!=0:\n",
    "                    vec.append( (\"%d%d\" % (pos+1, nuclIdx+1), val) )\n",
    "        vecs.append( vec )\n",
    "\n",
    "    lines = []\n",
    "    for vec in vecs:\n",
    "        vec = [\"%s:%s\" % (x,y) for x,y in vec]\n",
    "        lines.append(\"0 \"+\" \".join(vec))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "seqsToChariSvml([\"CTTCTTCAAGGTAACTGCAGA\", \"CTTCTTCAAGGTAACTGGGGG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CRISPRscan\n",
    "\n",
    "paramsCRISPRscan = [\n",
    "# converted excel table of logistic regression weights with 1-based positions\n",
    "('AA',18,-0.097377097),\n",
    "('TT',18,-0.094424075),('TT',13,-0.08618771),('CT',26,-0.084264893),('GC',25,-0.073453609),\n",
    "('T',21,-0.068730497),('TG',23,-0.066388075),('AG',23,-0.054338456),('G',30,-0.046315914),\n",
    "('A',4,-0.042153521),('AG',34,-0.041935908),('GA',34,-0.037797707),('A',18,-0.033820432),\n",
    "('C',25,-0.031648353),('C',31,-0.030715556),('G',1,-0.029693709),('C',16,-0.021638609),\n",
    "('A',14,-0.018487229),('A',11,-0.018287292),('T',34,-0.017647692),('AA',10,-0.016905415),\n",
    "('A',19,-0.015576499),('G',34,-0.014167123),('C',30,-0.013182733),('GA',31,-0.01227989),\n",
    "('T',24,-0.011996172),('A',15,-0.010595296),('G',4,-0.005448869),('GG',9,-0.00157799),\n",
    "('T',23,-0.001422243),('C',15,-0.000477727),('C',26,-0.000368973),('T',27,-0.000280845),\n",
    "('A',31,0.00158975),('GT',18,0.002391744),('C',9,0.002449224),('GA',20,0.009740799),\n",
    "('A',25,0.010506405),('A',12,0.011633235),('A',32,0.012435231),('T',22,0.013224035),\n",
    "('C',20,0.015089514),('G',17,0.01549378),('G',18,0.016457816),('T',30,0.017263162),\n",
    "('A',13,0.017628924),('G',19,0.017916844),('A',27,0.019126815),('G',11,0.020929039),\n",
    "('TG',3,0.022949996),('GC',3,0.024681785),('G',14,0.025116714),('GG',10,0.026802158),\n",
    "('G',12,0.027591138),('G',32,0.03071249),('A',22,0.031930909),('G',20,0.033957008),\n",
    "('C',21,0.034262921),('TT',17,0.03492881),('T',13,0.035445171),('G',26,0.036146649),\n",
    "('A',24,0.037466478),('C',22,0.03763162),('G',16,0.037970942),('GG',12,0.041883009),\n",
    "('TG',18,0.045908991),('TG',31,0.048136812),('A',35,0.048596259),('G',15,0.051129717),\n",
    "('C',24,0.052972314),('TG',15,0.053372822),('GT',11,0.053678436),('GC',9,0.054171402),\n",
    "('CA',30,0.057759851),('GT',24,0.060952114),('G',13,0.061360905),('CA',24,0.06221937),\n",
    "('AG',10,0.063717093),('G',10,0.067739182),('C',13,0.069495944),('GT',31,0.07342535),\n",
    "('GG',13,0.074355848),('C',27,0.079933922),('G',27,0.085151052),('CC',21,0.088919601),\n",
    "('CC',23,0.095072286),('G',22,0.10114438),('G',24,0.105488325),('GT',23,0.106718563),\n",
    "('GG',25,0.111559441),('G',9,0.114600681)]\n",
    "\n",
    "def calcCrisprScanScores(seqs):\n",
    "    \"\"\" input is a 35bp long sequence: 6bp 5', 20bp guide, 3 bp PAM and 6bp 3'\n",
    "    >>> calcCrisprScanScores([\"TCCTCTGGTGGCGCTGCTGGATGGACGGGACTGTA\"])\n",
    "    [77]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)==35)\n",
    "        intercept = 0.183930943629\n",
    "        score = intercept\n",
    "        for modelSeq, pos, weight in paramsCRISPRscan:\n",
    "            subSeq = seq[pos-1:pos+len(modelSeq)-1]\n",
    "            if subSeq==modelSeq:\n",
    "                score += weight\n",
    "        scores.append(int(100*score))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.scatter(df['FrameShift_IndelPhi'],df['FrameShift_FORECasT'],s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'dataset', u'guide', u'seq', u'modFreq', u'db',\n",
      "       u'position', u'longSeq100Bp', u'chariRank', u'chariRaw', u'crisprScan',\n",
      "       u'doench', u'drsc', u'finalGc6', u'finalGg', u'fusi', u'mh', u'oof',\n",
      "       u'ssc', u'wang', u'wangOrig', u'wuCrispr', u'Deep_score',\n",
      "       u'FrameShift_IndelPhi', u'Deep.oscar', u'Doench_score', u'SSC_score',\n",
      "       u'AA.loc', u'SIFT.score', u'Domain', u'Helix', u'Sheet',\n",
      "       u'PROVEAN.score', u'Pho.kde', u'Ace.kde'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_old = pd.read_csv('Testing_chari2015_293T_wei.csv')\n",
    "\n",
    "print df_old.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this library re-implements the efficiency scoring functions of these articles:\n",
    "\n",
    "# - WangSvm: Wang et al, Science 2014, PMID 24336569, no website\n",
    "# - Doench: Doench et al, Nat Biotech 2014, PMID 25184501, http://www.broadinstitute.org/rnai/public/analysis-tools/sgrna-design\n",
    "# - CrisprScan: Moreno-Mateos, Nat Meth 2015, PMID 26322839, http://crisprscan.org\n",
    "# - ssc: Xu et al, Gen Res 2015, PMID 26063738, http://crispr.dfci.harvard.edu/SSC/\n",
    "# - Chari: Chari et al, PMID 26167643 http://crispr.med.harvard.edu/sgRNAScorer\n",
    "# - Fusi: Fusi et al, prepublication manuscript on bioarxiv, http://dx.doi.org/10.1101/021568 http://research.microsoft.com/en-us/projects/azimuth/, only available as a web API\n",
    "# - Housden: Housden et al, PMID 26350902, http://www.flyrnai.org/evaluateCrispr/\n",
    "# - OOF: Microhomology and out-of-frame score from Bae et al, Nat Biotech 2014 , PMID24972169 http://www.rgenome.net/mich-calculator/\n",
    "# - Wu-Crispr: Wong et al, PMID, http://www.genomebiology.com/2015/16/1/218\n",
    "\n",
    "# the input are 100bp sequences that flank the basepair just 5' of the PAM +/-50bp.\n",
    "# so 50bp 5' of the PAM, and 47bp 3' of the PAM -> 100bp\n",
    "\n",
    "# this module uses pipes to feed data into some programs\n",
    "# If you run too many sequences at once, it may hang. Increase the BUFSIZE variable in this case.\n",
    "\n",
    "from subprocess import Popen, PIPE, STDOUT, check_output, CalledProcessError, call\n",
    "import platform, math, tempfile, bisect, sys, os, logging, types, optparse, shutil\n",
    "from os.path import dirname, join, basename, isfile, expanduser, isdir, abspath\n",
    "from math import log10\n",
    "\n",
    "import urllib2, pickle\n",
    "import json\n",
    "\n",
    "fusiDir = join(dirname(__file__), \"bin/fusiDoench\")\n",
    "sys.path.insert(0, join(fusiDir, \"analysis\"))\n",
    "\n",
    "import model_comparison\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# global that points to the crispor 'bin' directory with the external executables\n",
    "# like libsvm and svmlight\n",
    "global binDir\n",
    "binDir = None\n",
    "\n",
    "# the name of a directory to use for caching some efficiency values that are slow to calculate\n",
    "# deactivated by default\n",
    "cacheDir = None\n",
    "\n",
    "# by default bindir is relative to the location of this library\n",
    "if binDir is None:\n",
    "    binDir = join(dirname(__file__), \"bin\")\n",
    "\n",
    "BUFSIZE = 10000000\n",
    "\n",
    "def setBinDir(path):\n",
    "    global binDir\n",
    "    binDir = path\n",
    "\n",
    "def setCacheDir(path):\n",
    "    global cacheDir\n",
    "    cacheDir = path\n",
    "\n",
    "def getBinPath(name, isDir=False):\n",
    "    \"\"\"\n",
    "    get the full pathname of a platform-specific binary, in the bin/ directory relative to this directory\n",
    "    \"\"\"\n",
    "    currPlatform = platform.system()\n",
    "    #myDir = dirname(join(__file__))\n",
    "    binPath = join(binDir, currPlatform, name)\n",
    "    if isDir and not isdir(binPath):\n",
    "        raise Exception(\"Could not find directory %s\" % binPath)\n",
    "    if not isDir and not isfile(binPath):\n",
    "        raise Exception(\"Could not find file %s\" % binPath)\n",
    "    return binPath\n",
    "\n",
    "def seqToVec(seq, offsets={\"A\":0,\"C\":1,\"G\":2,\"T\":3}):\n",
    "    \"\"\" convert a x bp sequence to a 4 * x 0/1 vector\n",
    "    >>> seqToVec(\"AAAAATTTTTGGGGGCCCCC\")\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
    "    \"\"\"\n",
    "    assert(len(seq)==20)\n",
    "    row = [0]*len(seq)*4\n",
    "    pseudoOffset = offsets[\"A\"]\n",
    "    for pos, nucl in enumerate(seq):\n",
    "        nucl = nucl.upper()\n",
    "        # treat N, Y, etc like \"A\". Happens very rarely.\n",
    "        nuclOffset = offsets.get(nucl, pseudoOffset)\n",
    "        vecPos = (pos*len(offsets))+nuclOffset\n",
    "        #if vecPos not in range(len(row)):\n",
    "            #ofh = open(\"temp.txt\", \"a\")\n",
    "            #ofh.write(str(vecPos)+\" \"+seq+\" \"+str(row)+\"pos %d, nucl %s\" % (pos, nucl)+\"\\n\")\n",
    "            #assert(False)\n",
    "        row[vecPos] = 1\n",
    "    return row\n",
    "\n",
    "def vecToSeqDicts(coefs):\n",
    "    \" convert a list of 80 floats to 20 dictionaries with A/C/T/G -> float \"\n",
    "    freqs = []\n",
    "    for i in range(0,20):\n",
    "        charFreqs = {}\n",
    "        for nucl, x in zip(\"ACGT\", range(0,4)):\n",
    "            freq = coefs[i*4+x]\n",
    "            if freq==0.0:\n",
    "                continue\n",
    "            charFreqs[nucl] = freq\n",
    "        freqs.append(charFreqs)\n",
    "    return freqs\n",
    "\n",
    "paramsCRISPRscan = [\n",
    "# converted excel table of logistic regression weights with 1-based positions\n",
    "('AA',18,-0.097377097),\n",
    "('TT',18,-0.094424075),('TT',13,-0.08618771),('CT',26,-0.084264893),('GC',25,-0.073453609),\n",
    "('T',21,-0.068730497),('TG',23,-0.066388075),('AG',23,-0.054338456),('G',30,-0.046315914),\n",
    "('A',4,-0.042153521),('AG',34,-0.041935908),('GA',34,-0.037797707),('A',18,-0.033820432),\n",
    "('C',25,-0.031648353),('C',31,-0.030715556),('G',1,-0.029693709),('C',16,-0.021638609),\n",
    "('A',14,-0.018487229),('A',11,-0.018287292),('T',34,-0.017647692),('AA',10,-0.016905415),\n",
    "('A',19,-0.015576499),('G',34,-0.014167123),('C',30,-0.013182733),('GA',31,-0.01227989),\n",
    "('T',24,-0.011996172),('A',15,-0.010595296),('G',4,-0.005448869),('GG',9,-0.00157799),\n",
    "('T',23,-0.001422243),('C',15,-0.000477727),('C',26,-0.000368973),('T',27,-0.000280845),\n",
    "('A',31,0.00158975),('GT',18,0.002391744),('C',9,0.002449224),('GA',20,0.009740799),\n",
    "('A',25,0.010506405),('A',12,0.011633235),('A',32,0.012435231),('T',22,0.013224035),\n",
    "('C',20,0.015089514),('G',17,0.01549378),('G',18,0.016457816),('T',30,0.017263162),\n",
    "('A',13,0.017628924),('G',19,0.017916844),('A',27,0.019126815),('G',11,0.020929039),\n",
    "('TG',3,0.022949996),('GC',3,0.024681785),('G',14,0.025116714),('GG',10,0.026802158),\n",
    "('G',12,0.027591138),('G',32,0.03071249),('A',22,0.031930909),('G',20,0.033957008),\n",
    "('C',21,0.034262921),('TT',17,0.03492881),('T',13,0.035445171),('G',26,0.036146649),\n",
    "('A',24,0.037466478),('C',22,0.03763162),('G',16,0.037970942),('GG',12,0.041883009),\n",
    "('TG',18,0.045908991),('TG',31,0.048136812),('A',35,0.048596259),('G',15,0.051129717),\n",
    "('C',24,0.052972314),('TG',15,0.053372822),('GT',11,0.053678436),('GC',9,0.054171402),\n",
    "('CA',30,0.057759851),('GT',24,0.060952114),('G',13,0.061360905),('CA',24,0.06221937),\n",
    "('AG',10,0.063717093),('G',10,0.067739182),('C',13,0.069495944),('GT',31,0.07342535),\n",
    "('GG',13,0.074355848),('C',27,0.079933922),('G',27,0.085151052),('CC',21,0.088919601),\n",
    "('CC',23,0.095072286),('G',22,0.10114438),('G',24,0.105488325),('GT',23,0.106718563),\n",
    "('GG',25,0.111559441),('G',9,0.114600681)]\n",
    "\n",
    "def calcCrisprScanScores(seqs):\n",
    "    \"\"\" input is a 35bp long sequence: 6bp 5', 20bp guide, 3 bp PAM and 6bp 3'\n",
    "    >>> calcCrisprScanScores([\"TCCTCTGGTGGCGCTGCTGGATGGACGGGACTGTA\"])\n",
    "    [77]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)==35)\n",
    "        intercept = 0.183930943629\n",
    "        score = intercept\n",
    "        for modelSeq, pos, weight in paramsCRISPRscan:\n",
    "            subSeq = seq[pos-1:pos+len(modelSeq)-1]\n",
    "            if subSeq==modelSeq:\n",
    "                score += weight\n",
    "        scores.append(int(100*score))\n",
    "    return scores\n",
    "\n",
    "def listToSvml(vec, res):\n",
    "    \"\"\" convert a list of values to a line in svml format line like \"+1 1:0.5 2:1.5 ...\n",
    "    \"\"\"\n",
    "    parts = [str(res)]\n",
    "    for i, val in enumerate(vec):\n",
    "        parts.append(\"%d:%d\" % (i+1, val))\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def calcWangSvmScores(seqs):\n",
    "    \"\"\"\n",
    "    Use the wang.model file to score sequences. Input is only the 20bp guide sequence.\n",
    "    Uses libsvm's svm-predict program, V2.6.\n",
    "    The score is inversed, so higher scores are better, like all other scores\n",
    "    The results here are off mostly by 1-5% from the results returned by the Wang et al source code.\n",
    "    I never found out why, there are no parameters for \"svm_predict\". Should not be due to a version\n",
    "    difference either, I'm using the same libsvm version as the e1071 R module.\n",
    "    This is necessary for a web server implementation as e1071 in R cannot read the model from a file.\n",
    "    The original implementation from the paper can be called with calcWangSvmScoresUsingR()\n",
    "    See compareWangScores.py:\n",
    "    The Pearson correlation between both ways to calculate the score is 97%.\n",
    "    Histogram of the score differences:\n",
    "    0.000000 ************************************************************ 3074\n",
    "    0.050000 ********************************* 1674\n",
    "    0.100000 ************ 612\n",
    "    0.150000 **** 191\n",
    "    0.200000 * 52\n",
    "    0.250000  7\n",
    "    0.300000  1\n",
    "    cat out/wangDiffs.tsv | cut -f4 | tr -d '-' | grep -v diff | textHistogram stdin stdout -real -binSize=0.05\n",
    "    >>> calcWangSvmScores([\"ATAGACCTACCTTGTTGAAG\"])\n",
    "    [60]\n",
    "    >>> calcWangSvmScores([\"NTAGACCTACCTTGTTGAAG\"])\n",
    "    [60]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    vecOrder = {\"A\":0, \"C\":1, \"T\":2, \"G\":3}\n",
    "\n",
    "    lines = []\n",
    "    for seq in seqs:\n",
    "        seq = seq.upper()\n",
    "        assert(len(seq)==20)\n",
    "        vec = seqToVec(seq, offsets=vecOrder)\n",
    "        lines.append(listToSvml(vec, 0))\n",
    "\n",
    "    dataIn = \"\\n\".join(lines)\n",
    "    binPath = getBinPath(\"svm-predict\")\n",
    "    modelFname = join(binDir, \"src\", \"wangSabatiniSvm\", \"wang.model\")\n",
    "    cmd = [binPath, \"-b\", \"1\", \"/dev/stdin\", modelFname, \"/dev/stdout\"]\n",
    "    proc = Popen(cmd,stdout=PIPE, stdin=PIPE, stderr=None, bufsize=BUFSIZE)\n",
    "    dataOut = proc.communicate(input=dataIn)[0]\n",
    "\n",
    "    lines = dataOut.splitlines()\n",
    "    for line in lines:\n",
    "        if line.startswith(\"labels\"):\n",
    "            continue\n",
    "        if line.startswith(\"Accuracy\"):\n",
    "            break\n",
    "        score = int(100*(1.0 - float(line.split()[-1])))\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# DOENCH SCORING \n",
    "doenchParams = [\n",
    "# pasted/typed table from PDF and converted to zero-based positions\n",
    "(1,'G',-0.2753771),(2,'A',-0.3238875),(2,'C',0.17212887),(3,'C',-0.1006662),\n",
    "(4,'C',-0.2018029),(4,'G',0.24595663),(5,'A',0.03644004),(5,'C',0.09837684),\n",
    "(6,'C',-0.7411813),(6,'G',-0.3932644),(11,'A',-0.466099),(14,'A',0.08537695),\n",
    "(14,'C',-0.013814),(15,'A',0.27262051),(15,'C',-0.1190226),(15,'T',-0.2859442),\n",
    "(16,'A',0.09745459),(16,'G',-0.1755462),(17,'C',-0.3457955),(17,'G',-0.6780964),\n",
    "(18,'A',0.22508903),(18,'C',-0.5077941),(19,'G',-0.4173736),(19,'T',-0.054307),\n",
    "(20,'G',0.37989937),(20,'T',-0.0907126),(21,'C',0.05782332),(21,'T',-0.5305673),\n",
    "(22,'T',-0.8770074),(23,'C',-0.8762358),(23,'G',0.27891626),(23,'T',-0.4031022),\n",
    "(24,'A',-0.0773007),(24,'C',0.28793562),(24,'T',-0.2216372),(27,'G',-0.6890167),\n",
    "(27,'T',0.11787758),(28,'C',-0.1604453),(29,'G',0.38634258),(1,'GT',-0.6257787),\n",
    "(4,'GC',0.30004332),(5,'AA',-0.8348362),(5,'TA',0.76062777),(6,'GG',-0.4908167),\n",
    "(11,'GG',-1.5169074),(11,'TA',0.7092612),(11,'TC',0.49629861),(11,'TT',-0.5868739),\n",
    "(12,'GG',-0.3345637),(13,'GA',0.76384993),(13,'GC',-0.5370252),(16,'TG',-0.7981461),\n",
    "(18,'GG',-0.6668087),(18,'TC',0.35318325),(19,'CC',0.74807209),(19,'TG',-0.3672668),\n",
    "(20,'AC',0.56820913),(20,'CG',0.32907207),(20,'GA',-0.8364568),(20,'GG',-0.7822076),\n",
    "(21,'TC',-1.029693),(22,'CG',0.85619782),(22,'CT',-0.4632077),(23,'AA',-0.5794924),\n",
    "(23,'AG',0.64907554),(24,'AG',-0.0773007),(24,'CG',0.28793562),(24,'TG',-0.2216372),\n",
    "(26,'GT',0.11787758),(28,'GG',-0.69774)]\n",
    "\n",
    "def calcDoenchScores(seqs):\n",
    "    \"\"\"\n",
    "    Code reproduced following paper's methods section. Thanks to Daniel McPherson for fixing it.\n",
    "    Input is a 30mer: 4bp 5', 20bp guide, 3bp PAM, 3bp 5'\n",
    "    \"\"\"\n",
    "    intercept =  0.59763615\n",
    "    gcHigh    = -0.1665878\n",
    "    gcLow     = -0.2026259\n",
    "\n",
    "    scores = []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)==30)\n",
    "        score = intercept\n",
    "\n",
    "        guideSeq = seq[4:24]\n",
    "        gcCount = guideSeq.count(\"G\") + guideSeq.count(\"C\")\n",
    "        if gcCount <= 10:\n",
    "            gcWeight = gcLow\n",
    "        if gcCount > 10:\n",
    "            gcWeight = gcHigh\n",
    "        score += abs(10-gcCount)*gcWeight\n",
    "\n",
    "        for pos, modelSeq, weight in doenchParams:\n",
    "            subSeq = seq[pos:pos+len(modelSeq)]\n",
    "            if subSeq==modelSeq:\n",
    "                score += weight\n",
    "        expScore = int(100*(1.0/(1.0+math.exp(-score))))\n",
    "        scores.append(expScore)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def calcSscScores(seqs):\n",
    "    \"\"\" calc the SSC scores from the paper Xu Xiao Chen Li Meyer Brown Lui Gen Res 2015 \n",
    "    Input is a 30mer, 20bp for the guide, 3bp PAM, 7bp 3' flanking\n",
    "    >>> calcSscScores([\"AGCAGGATAGTCCTTCCGAGTGGAGGGAGG\"])\n",
    "    [0.182006]\n",
    "    \"\"\"\n",
    "    assert(len(seqs)!=0) # need at least one sequence\n",
    "    strList = []\n",
    "    for s in seqs:\n",
    "        assert(len(s)==30)\n",
    "        strList.append(\"%s 0 0 + dummy\" % s)\n",
    "    sscIn = \"\\n\".join(strList)\n",
    "\n",
    "    # ../../Darwin/SSC -i /dev/stdin  -o /dev/stdout -l 30 -m matrix/human_mouse_CRISPR_KO_30bp.matrix \n",
    "    # AGCAGGATAGTCCTTCCGAGTGGAGGGAGG  187 216 -   MYC_exon3_hg19\n",
    "    # AGCAGGATAGTCCTTCCGAGTGGAGGGAGG  0 0 -   t\n",
    "    # AGCAGGATAGTCCTTCCGAGTGGAGGGAGG  187 216 -   MYC_exon3_hg19  0.182006\n",
    "    sscPath = getBinPath(\"SSC\")\n",
    "    matPath = join(binDir, \"src\", \"SSC0.1\", \"matrix\", \"human_mouse_CRISPR_KO_30bp.matrix\")\n",
    "    cmd = [sscPath, \"-i\", \"/dev/stdin\", \"-o\", \"/dev/stdout\", \"-l\", \"30\", \"-m\", matPath]\n",
    "    try:\n",
    "        stdout, stderr = Popen(cmd, stdin=PIPE, stdout=PIPE, bufsize=BUFSIZE).communicate(sscIn)\n",
    "    except OSError:\n",
    "        raise Exception(\"Cannot run command %s\" % \" \".join(cmd))\n",
    "    scores = {}\n",
    "    i = 0\n",
    "    for lineIdx, line in enumerate(stdout.split(\"\\n\")):\n",
    "        fs = line.split()\n",
    "        if \"Processing failed\" in line:\n",
    "            raise Exception(\"SSC returned error, line %d\" % lineIdx)\n",
    "        seq, score = fs[0], float(fs[-1])\n",
    "        scores[seq] = score\n",
    "        lineIdx += 1\n",
    "        if lineIdx==len(seqs):\n",
    "            break\n",
    "\n",
    "    scoreList = []\n",
    "    # make sure we got a score for each input sequence\n",
    "    for s in seqs:\n",
    "        scoreList.append(scores[s])\n",
    "        \n",
    "    return scoreList\n",
    "\n",
    "def seqsToChariSvml(seqs):\n",
    "    \"\"\" partially copied from generateSVMFile.FASTA.py in the Chari et al source code\n",
    "    >>> seqsToChariSvml([\"CTTCTTCAAGGTAACTGCAGA\", \"CTTCTTCAAGGTAACTGGGGG\"])\n",
    "    '0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 183:1 194:1 201:1 214:1\\\\n0 13:1 22:1 32:1 43:1 52:1 62:1 73:1 84:1 94:1 101:1 111:1 122:1 134:1 144:1 153:1 162:1 171:1 181:1 191:1 201:1 211:1'\n",
    "    \"\"\"\n",
    "    vecs = []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)==21)\n",
    "        vec = []\n",
    "        # end index\n",
    "        for pos in range(0, 21):\n",
    "            for nuclIdx, char in enumerate(\"GTCA\"):\n",
    "                val = int(seq[pos]==char)\n",
    "                if val!=0:\n",
    "                    vec.append( (\"%d%d\" % (pos+1, nuclIdx+1), val) )\n",
    "        vecs.append( vec )\n",
    "\n",
    "    lines = []\n",
    "    for vec in vecs:\n",
    "        vec = [\"%s:%s\" % (x,y) for x,y in vec]\n",
    "        lines.append(\"0 \"+\" \".join(vec))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "chariRanges = None\n",
    "\n",
    "def convertChariToRankPerc(score):\n",
    "    \"\"\"\n",
    "    convert chari score to rank percent using only 2 digits precision. A lot faster than\n",
    "    the version in the paper.\n",
    "    \"\"\"\n",
    "    global chariRanges\n",
    "    if chariRanges is None:\n",
    "        # parse values\n",
    "        fname = join(binDir, \"src\", \"sgRNA.Scorer.1.0\", \"Hg19.RefFlat.Genes.75bp.NoUTRs.SPSites.SVMOutput.ranges.txt\")\n",
    "        ranges = open(fname).read().splitlines()\n",
    "        ranges = [float(x) for x in ranges]\n",
    "\n",
    "    # use bisection to find the right value\n",
    "    fastPerc = bisect.bisect(ranges, score)-1\n",
    "\n",
    "    # the old, slow way\n",
    "    #fname = join(binDir, \"src\", \"sgRNA.Scorer.1.0\", \"Hg19.RefFlat.Genes.75bp.NoUTRs.SPSites.SVMOutput.txt\")\n",
    "    #allData = open(fname).read().splitlines()\n",
    "    #allData = np.array([float(x) for x in allData])\n",
    "    #slowPerc = 100.0*(allData[allData < score].size / float(allData.size))\n",
    "    return fastPerc\n",
    "\n",
    "def calcChariScores(seqs, baseDir=\".\"):\n",
    "    \"\"\" return dict with chari 2015 scores, returns two lists (rawScores, rankPercent)\n",
    "    input seqs have lengths 21bp: 20 bp guide + 1bp first from PAM\n",
    "    >>> calcChariScores([\"CTTCTTCAAGGTAACTGCAGA\", \"CTTCTTCAAGGTAACTGGGGG\"])\n",
    "    ([0.54947621, 0.58604487], [80, 81])\n",
    "    \"\"\"\n",
    "    # this is a rewritten version of scoreMySites.py in the Chari2015 suppl files\n",
    "    chariDir = join(binDir, \"src\", \"sgRNA.Scorer.1.0\")\n",
    "    modelFname = join(chariDir,'293T.HiSeq.SP.Nuclease.100.SVM.Model.txt')\n",
    "    dataIn = seqsToChariSvml(seqs)\n",
    "    #print repr(dataIn)\n",
    "\n",
    "    #tempFh = tempfile.NamedTemporaryFile()\n",
    "    tempFname = tempfile.mktemp()\n",
    "    #tempFh = open(\"temp3.txt\", \"w\")\n",
    "    tempFh = open(tempFname, \"w\")\n",
    "    tempFh.write(dataIn+\"\\n\")\n",
    "    tempFh.close()\n",
    "    #tempFname = tempFh.name\n",
    "    #tempFh.close()\n",
    "\n",
    "    #outTempFh = tempfile.NamedTemporaryFile()\n",
    "    #outName = outTempFh.name\n",
    "    outName = tempfile.mktemp()\n",
    "\n",
    "    svmlPath = getBinPath(\"svm_classify\")\n",
    "    cmd = [svmlPath, \"-v\", \"0\", tempFname, modelFname, outName]\n",
    "    try:\n",
    "        proc = call(cmd)\n",
    "    except CalledProcessError:\n",
    "        raise Exception(\"Could not run command '%s'\" % (\" \".join(cmd)))\n",
    "\n",
    "    #print \" \".join(cmd)\n",
    "    dataOut = open(outName).read()\n",
    "    os.remove(outName)\n",
    "    os.remove(tempFname)\n",
    "\n",
    "    scores = []\n",
    "    ranks = []\n",
    "    for line in dataOut.splitlines():\n",
    "        score = float(line)\n",
    "        scores.append(score)\n",
    "        ranks.append(convertChariToRankPerc(score))\n",
    "    return scores, ranks\n",
    "\n",
    "    #cmd = svmlight.classify(model, vecs)\n",
    "    #return scores\n",
    "\n",
    "def writeDict(d, fname):\n",
    "    \" write dict as a tab file \"\n",
    "    if not isdir(dirname(fname)):\n",
    "        logging.debug(\"Cannot write %s, no caching of efficiency scores\" % fname)\n",
    "        return\n",
    "\n",
    "    ofh = open(fname, \"w\")\n",
    "    for k, v in d.iteritems():\n",
    "        if type(v)==types.TupleType:\n",
    "            ofh.write(\"%s\\t%s\\n\" % (k, \"\\t\".join([str(x) for x in v])))\n",
    "        else:\n",
    "            ofh.write(\"%s\\t%s\\n\" % (k, str(v)))\n",
    "    ofh.close()\n",
    "\n",
    "def readDict(fname, isFloat=True):\n",
    "    \" read dict from a tab sep file \"\n",
    "    if not isfile(fname):\n",
    "        logging.debug(\"%s does not exist. Returning empty dict\" % fname)\n",
    "        return {}\n",
    "\n",
    "    logging.info(\"Reading %s\" %fname)\n",
    "    data = {}\n",
    "    for line in open(fname):\n",
    "        fs = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if len(fs)==2:\n",
    "            k, v = fs\n",
    "            if isFloat:\n",
    "                v = float(v)\n",
    "        else:\n",
    "            k = fs[0]\n",
    "            v = tuple(fs[1:])\n",
    "            if isFloat:\n",
    "                v = tuple([float(x) for x in v])\n",
    "        data[k] = v\n",
    "    return data\n",
    "\n",
    "class ScoreCache:\n",
    "    \"\"\"\n",
    "    a cache of eff scores, kept on disk. Can avoid slow calculations by keeping\n",
    "    the value of the score in a tab-sep file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scoreName):\n",
    "        self.cacheFname = join(cacheDir, \"%s.tab\" % scoreName)\n",
    "        scoreCache = readDict(self.cacheFname, isFloat=True)\n",
    "        self.scoreCache = scoreCache\n",
    "\n",
    "    def findNewSeqs(self, seqs):\n",
    "        \"\"\" get seqs that are not in cache. If all are, return the list of scores.\n",
    "        Otherwise return None for the scores.\n",
    "        Returns tuple (seqs, scores)\n",
    "        \"\"\"\n",
    "        self.allSeqs = seqs\n",
    "        newSeqs = set()\n",
    "        for s in seqs:\n",
    "            if not s in self.scoreCache:\n",
    "                newSeqs.add(s)\n",
    "\n",
    "        scoreList = None\n",
    "        if len(newSeqs)==0:\n",
    "            scoreList = [self.scoreCache[s] for s in seqs]\n",
    "        self.newSeqs = newSeqs\n",
    "        return newSeqs, scoreList\n",
    "\n",
    "    def mergeIntoCache(self, newScores):\n",
    "        # create final result merging cache and newly obtained scores\n",
    "        scoreList = []\n",
    "        assert(len(newScores)==len(self.newSeqs))\n",
    "        newScoreDict = dict(zip(self.newSeqs, newScores))\n",
    "\n",
    "        for s in self.allSeqs:\n",
    "            if s in newScoreDict:\n",
    "                scoreList.append(newScoreDict[s])\n",
    "            else:\n",
    "                scoreList.append(self.scoreCache[s])\n",
    "\n",
    "        self.scoreCache.update(newScoreDict)\n",
    "        writeDict(self.scoreCache, self.cacheFname)\n",
    "        return scoreList\n",
    "\n",
    "def sendFusiRequest(seqs):\n",
    "    \"\"\"\n",
    "    obtain the fusi score as calculated by Fusi et al's webservice\n",
    "    Needs a file fusiKey.txt in current directory or a file ~/.fusiKey.txt in user's home directory.\n",
    "    # test deactivated - server is not working\n",
    "    >> sendFusiRequest([ \"GGGAGGCTGCTTTACCCGCTGTGGGGGCGC\", \"GGGAGGCTGCTTTACCCGCTGTGGGGGCGC\"])\n",
    "    [60, 60]\n",
    "    \"\"\"\n",
    "    keyFname = expanduser(\"~/.fusiKey.txt\")\n",
    "    if not isfile(keyFname):\n",
    "        keyFname = \"fusiKey.txt\"\n",
    "    if not isfile(keyFname):\n",
    "        raise Exception(\"No ./fusiKey.txt and ~/.fusiKey.txt file found. Request an API key from azimuth@microsoft.com, write it into this file (single line) and retry\")\n",
    "\n",
    "    api_key = open(keyFname, \"r\").read().strip()\n",
    "    paramList = [ [seq, \"-1\", \"-1\"] for seq in seqs]\n",
    "                        #\"Values\": [ [ \"GGGAGGCTGCTTTACCCGCTGTGGGGGCGC\", \"-1\", \"-1\" ] ]\n",
    "    data =  {\n",
    "\n",
    "            \"Inputs\": {\n",
    "\n",
    "                    \"input1\":\n",
    "                    {\n",
    "                        \"ColumnNames\": [\"sequence\", \"cutsite\", \"percentpeptide\"],\n",
    "                        \"Values\": paramList,\n",
    "                    },        },\n",
    "                \"GlobalParameters\": {\n",
    "    }\n",
    "        }\n",
    "\n",
    "    body = str.encode(json.dumps(data))\n",
    "\n",
    "    url = 'https://ussouthcentral.services.azureml.net/workspaces/ee5485c1d9814b8d8c647a89db12d4df/services/c24d128abfaf4832abf1e7ef45db4b54/execute?api-version=2.0&details=true'\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "    req = urllib2.Request(url, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib2.urlopen(req)\n",
    "\n",
    "        # If you are using Python 3+, replace urllib2 with urllib.request in the above code:\n",
    "        # req = urllib.request.Request(url, body, headers) \n",
    "        # response = urllib.request.urlopen(req)\n",
    "\n",
    "        dataList = json.loads(response.read())[\"Results\"][\"output2\"][\"value\"][\"Values\"]\n",
    "        scores = [int(round(100*float(x[0]))) for x in dataList]\n",
    "        return scores\n",
    "\n",
    "    except urllib2.HTTPError, error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "        # Print the headers - they include the request ID and the timestamp, which are useful for debugging the failure\n",
    "        print(error.info())\n",
    "\n",
    "        print(json.loads(error.read())) \n",
    "        sys.exit(1)\n",
    "\n",
    "def trimSeqs(seqs, fiveFlank, threeFlank):\n",
    "    \"\"\" given a list of 100bp sequences, return a list of sequences with the\n",
    "    given number of basepairs 5' and 3' added from the middle position (pos 50) of\n",
    "    the sequences. Remove all sequences that contain an \"N\" character.\n",
    "    \"\"\"\n",
    "    trimSeqs = []\n",
    "    for s in seqs:\n",
    "        seq = s[50+fiveFlank:50+threeFlank].upper()\n",
    "        if \"N\" in seq:\n",
    "            continue\n",
    "        trimSeqs.append(seq)\n",
    "    return trimSeqs\n",
    "\n",
    "def iterSvmRows(seqs):\n",
    "    \"\"\" translate sequences to wang/sabatini/lander paper representation\n",
    "    >>> list(iterSvmRows([\"ATAGACCTACCTTGTTGAAG\"]))\n",
    "    [['SEQ', 'BP1A', 'BP1C', 'BP1T', 'BP1G', 'BP2A', 'BP2C', 'BP2T', 'BP2G', 'BP3A', 'BP3C', 'BP3T', 'BP3G', 'BP4A', 'BP4C', 'BP4T', 'BP4G', 'BP5A', 'BP5C', 'BP5T', 'BP5G', 'BP6A', 'BP6C', 'BP6T', 'BP6G', 'BP7A', 'BP7C', 'BP7T', 'BP7G', 'BP8A', 'BP8C', 'BP8T', 'BP8G', 'BP9A', 'BP9C', 'BP9T', 'BP9G', 'BP10A', 'BP10C', 'BP10T', 'BP10G', 'BP11A', 'BP11C', 'BP11T', 'BP11G', 'BP12A', 'BP12C', 'BP12T', 'BP12G', 'BP13A', 'BP13C', 'BP13T', 'BP13G', 'BP14A', 'BP14C', 'BP14T', 'BP14G', 'BP15A', 'BP15C', 'BP15T', 'BP15G', 'BP16A', 'BP16C', 'BP16T', 'BP16G', 'BP17A', 'BP17C', 'BP17T', 'BP17G', 'BP18A', 'BP18C', 'BP18T', 'BP18G', 'BP19A', 'BP19C', 'BP19T', 'BP19G', 'BP20A', 'BP20C', 'BP20T', 'BP20G'], ['ATAGACCTACCTTGTTGAAG', 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]]\n",
    "    \"\"\"\n",
    "    offsets = {\"A\":0,\"C\":1,\"T\":2,\"G\":3}\n",
    "    # construct and write header\n",
    "    headers = [\"SEQ\"]\n",
    "    fields = []\n",
    "    for i in range(1, 21):\n",
    "        for n in [\"A\", \"C\", \"T\", \"G\"]:\n",
    "            fields.append(\"BP\"+str(i)+n)\n",
    "    headers.extend(fields)\n",
    "    yield headers\n",
    "\n",
    "    for seq in seqs:\n",
    "        row = []\n",
    "        row.extend([0]*80)\n",
    "        for pos, nucl in enumerate(seq):\n",
    "            nuclOffset = offsets[nucl]\n",
    "            row[pos*4+nuclOffset] = 1\n",
    "        assert(len(seq)==20)\n",
    "        row.insert(0, seq)\n",
    "        yield row\n",
    "\n",
    "def writeSvmRows(seqs, fname):\n",
    "    \"\"\" write the seqs in wang/sabatini SVM format to a file\n",
    "    #>>> writeSvmRows([\"ATAGACCTACCTTGTTGAAG\"])\n",
    "    \"\"\"\n",
    "    tmpFile = open(fname, \"w\")\n",
    "    #tmpFile = tempfile.NamedTemporaryFile(prefix=\"svmR\")\n",
    "    for row in iterSvmRows(seqs):\n",
    "        tmpFile.write(\"\\t\".join([str(x) for x in row]))\n",
    "        tmpFile.write(\"\\n\")\n",
    "    tmpFile.close()\n",
    "\n",
    "def parseSvmOut(fname):\n",
    "    \" parse R SVM output file, return as dict seq -> score \"\n",
    "    data = {}\n",
    "    for line in open (fname):\n",
    "        fs = line.strip().split()\n",
    "        seq, score = fs\n",
    "        seq = seq.strip('\"')\n",
    "        score = score.strip('\"')\n",
    "        data[seq] = float(score)\n",
    "    return data\n",
    "\n",
    "def calcWangSvmScoresUsingR(seqs):\n",
    "    \"\"\"\n",
    "    returns the SVM-calculated efficiency scores from the Wang/Sabatini/Lander paper\n",
    "    This is using their original source code\n",
    "    We're inversing the score so higher scores are better\n",
    "    \"\"\"\n",
    "    writeSvmRows(seqs, \"/tmp/temp.txt\")\n",
    "    wangSabDir = join(binDir, \"src\", \"wangSabatiniSvm\")\n",
    "    cmd = \"cd %s; R --slave --no-save -f scorer.R --args /tmp/temp.txt /tmp/temp.out\" % wangSabDir\n",
    "    print \"running\", cmd\n",
    "    assert(os.system(cmd)==0)\n",
    "    scoreDict = parseSvmOut(\"/tmp/temp.out\")\n",
    "    scoreList = []\n",
    "    for s in seqs:\n",
    "        scoreList.append(1.0 - scoreDict[s])\n",
    "    return scoreList\n",
    "\n",
    "def cacheScores(scoreName, scoreFunc, seqs):\n",
    "    \" run scoreFunc on seqs, using an on-disk score cache to improve speed \"\n",
    "    if cacheDir is None:\n",
    "        return scoreFunc(seqs)\n",
    "    \n",
    "    logging.info(\"Getting %d scores of type %s\" % (len(seqs), scoreName))\n",
    "    effCache = ScoreCache(scoreName)\n",
    "    newSeqs, allScoresFound = effCache.findNewSeqs(seqs)\n",
    "    if allScoresFound is not None:\n",
    "        return allScoresFound\n",
    "    else:\n",
    "        newScores = scoreFunc(newSeqs)\n",
    "    allScores = effCache.mergeIntoCache(newScores)\n",
    "    assert(len(allScores)==len(seqs))\n",
    "    return allScores\n",
    "\n",
    "def calcAllBaeScores(seqs):\n",
    "    \"\"\"\n",
    "    run seqs through calcMicroHomolScore()\n",
    "    PAM-site has to start at the nucleotide exactly in the middle of the sequence.\n",
    "    \"\"\"\n",
    "    mhScores, oofScores, allMhSeqs = [], [], []\n",
    "    for seq in seqs:\n",
    "        assert(len(seq)%2==0)\n",
    "        mhScore, oof, mhSeqs = calcMicroHomolScore(seq, len(seq)/2)\n",
    "        mhScores.append(mhScore)\n",
    "        oofScores.append(oof)\n",
    "        allMhSeqs.append(mhSeqs)\n",
    "    return mhScores, oofScores, allMhSeqs\n",
    "\n",
    "def calcMicroHomolScore(seq, left):\n",
    "    \"\"\" calculate the micro homology and out-of-frame score for a breakpoint in a 60-80mer\n",
    "    See http://www.nature.com/nmeth/journal/v11/n7/full/nmeth.3015.html\n",
    "    Source code adapted from Supp File 1\n",
    "    returns micro-homology score, out-of-frame score and a list of tuples:\n",
    "    (sequence, score)\n",
    "    From the manuscript:\n",
    "    \"On the basis of these observations, we developed a simple formula and a\n",
    "    computer program (Supplementary Fig. 3) to predict the deletion patterns\n",
    "    at a given nuclease target site that are associated with microhomology of\n",
    "    at least two bases (Fig. 1b and Supplementary Note). We assigned a pattern\n",
    "    score to each deletion pattern and a microhomology score (equaling the sum\n",
    "    of pattern scores) to each target site. We then obtained an out-of-frame\n",
    "    score at a given site by dividing the sum of pattern scores assigned to\n",
    "    frameshifting deletions by the microhomology score.\"\n",
    "    \"\"\"\n",
    "    seq = seq.upper()\n",
    "    length_weight=20.0\n",
    "    right=len(seq)-int(left)\n",
    "\n",
    "    duplRows = []\n",
    "    seqs = []\n",
    "    for k in reversed(range(2,left)):\n",
    "        for j in range(left,left+right-k+1): \n",
    "            for i in range(0,left-k+1):\n",
    "                if seq[i:i+k]==seq[j:j+k]:\n",
    "                    length = j-i\n",
    "                    dupSeq = seq[i:i+k]\n",
    "                    duplRows.append( (dupSeq, i, i+k, j, j+k, length) )\n",
    "\n",
    "    if len(duplRows)==0:\n",
    "        return 0, 0, []\n",
    "\n",
    "    ### After searching out all microhomology patterns, duplication should be removed!! \n",
    "    sum_score_3=0\n",
    "    sum_score_not_3=0\n",
    "\n",
    "    for i in range(len(duplRows)):\n",
    "        n=0\n",
    "        scrap, left_start, left_end, right_start, right_end, length = duplRows[i]\n",
    "\n",
    "        for j in range(i):\n",
    "            _, left_start_ref, left_end_ref, right_start_ref, right_end_ref, _ = duplRows[j]\n",
    "\n",
    "            if (left_start >= left_start_ref) and \\\n",
    "               (left_end <= left_end_ref) and \\\n",
    "               (right_start >= right_start_ref) and \\\n",
    "               (right_end <= right_end_ref) and \\\n",
    "               (left_start - left_start_ref) == (right_start - right_start_ref) and \\\n",
    "               (left_end - left_end_ref) == (right_end - right_end_ref):\n",
    "                    n+=1\n",
    "\n",
    "        if n != 0:\n",
    "            continue\n",
    "\n",
    "        length_factor = round(1/math.exp(length/length_weight),3)\n",
    "        num_GC=scrap.count(\"G\")+scrap.count(\"C\")\n",
    "        score = 100*length_factor*((len(scrap)-num_GC)+(num_GC*2))\n",
    "\n",
    "        if (length % 3)==0:\n",
    "            sum_score_3+=score\n",
    "        elif (length % 3)!=0:\n",
    "            sum_score_not_3+=score\n",
    "\n",
    "        newSeq = seq[0:left_end] + ('-'*length) + seq[right_end:]\n",
    "        seqs.append( (float(score), newSeq) )\n",
    "\n",
    "    mhScore = sum_score_3+sum_score_not_3\n",
    "    oofScore = ((sum_score_not_3)*100) / (sum_score_3+sum_score_not_3)\n",
    "    return int(mhScore), int(oofScore), seqs\n",
    "\n",
    "def forceWrapper(func, seqs):\n",
    "    \"\"\"\n",
    "    run func over seqs. If any exception occurs, return a list of -1s for all seqs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return func(seqs)\n",
    "    except:\n",
    "        return [-1]*len(seqs)\n",
    "\n",
    "def calcAllScores(seqs, addOpt=[], doAll=False):\n",
    "    \"\"\"\n",
    "    given 100bp sequences (50bp 5' of PAM, 50bp 3' of PAM) calculate all efficiency scores\n",
    "    and return as a dict scoreName -> list of scores (same order).\n",
    "    >>> sorted(calcAllScores([\"CCACGTCTCCACACATCAGCACAACTACGCAGCGCCTCCCTCCACTCGGAAGGACTATCCTGCTGCCAAGAGGGTCAAGTTGGACAGTGTCAGAGTCCTG\"]).items())\n",
    "    [('chariRank', [54]), ('chariRaw', [-0.15504833]), ('crisprScan', [39]), ('doench', [10]), ('finalGc6', [1]), ('finalGg', [0]), ('fusi', [56]), ('housden', [6.3]), ('mh', [4404]), ('oof', [51]), ('ssc', [-0.035894]), ('wang', [66]), ('wuCrispr', [0])]\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    for s in seqs:\n",
    "        if len(s)!=100:\n",
    "            raise Exception(\"sequence %s is %d bp and not 100 bp long\" % (s, len(s)))\n",
    "\n",
    "    guideSeqs = trimSeqs(seqs, -20, 0)\n",
    "\n",
    "    logging.debug(\"Housden scores\")\n",
    "    scores[\"housden\"] = calcHousden(trimSeqs(seqs, -20, 0))\n",
    "    #scores[\"drsc\"] = scores[\"housden\"] # for backwards compatibility with my old scripts.\n",
    "\n",
    "    logging.debug(\"Wang scores\")\n",
    "    scores[\"wang\"] = cacheScores(\"wang\", calcWangSvmScores, guideSeqs)\n",
    "    if \"wangOrig\" in addOpt or doAll:\n",
    "        scores[\"wangOrig\"] = cacheScores(\"wangOrig\", calcWangSvmScoresUsingR, guideSeqs)\n",
    "\n",
    "    logging.debug(\"Doench score\")\n",
    "    scores[\"doench\"] = calcDoenchScores(trimSeqs(seqs, -24, 6))\n",
    "\n",
    "    logging.debug(\"Fusi score\")\n",
    "    scores[\"fusi\"] = calcFusiDoench(trimSeqs(seqs, -24, 6))\n",
    "\n",
    "    logging.debug(\"SSC score\")\n",
    "    scores[\"ssc\"] = calcSscScores(trimSeqs(seqs, -20, 10))\n",
    "\n",
    "    logging.debug(\"CrisprScan score\")\n",
    "    scores[\"crisprScan\"] = calcCrisprScanScores(trimSeqs(seqs, -26, 9))\n",
    "\n",
    "    logging.debug(\"wuCrispr score\")\n",
    "    scores[\"wuCrispr\"] = calcWuCrisprScore(trimSeqs(seqs, -20, 4))\n",
    "\n",
    "    logging.debug(\"Chari score\")\n",
    "    chariScores = calcChariScores(trimSeqs(seqs, -20, 1))\n",
    "    scores[\"chariRaw\"] = chariScores[0]\n",
    "    scores[\"chariRank\"] = chariScores[1]\n",
    "\n",
    "    logging.debug(\"OOF scores\")\n",
    "    mh, oof, mhSeqs = calcAllBaeScores(trimSeqs(seqs, -40, 40))\n",
    "    scores[\"oof\"] = oof\n",
    "    scores[\"mh\"] = mh\n",
    "\n",
    "    scores[\"finalGc6\"] = [int(s.count(\"G\")+s.count(\"C\") >= 4) for s in trimSeqs(seqs, -6, 0)]\n",
    "    scores[\"finalGg\"] = [int(s==\"GG\") for s in trimSeqs(seqs, -2, 0)]\n",
    "\n",
    "    # the fusi score calculated by the Microsoft Research Server is not run by\n",
    "    # default, requires an apiKey\n",
    "    if \"fusiOnline\" in addOpt or doAll:\n",
    "        scores[\"fusiOnline\"] = cacheScores(\"fusi\", sendFusiRequest, trimSeqs(seqs, -24, 6))\n",
    "    # by default, I use the python source code sent to me by John Doench\n",
    "\n",
    "\n",
    "    # fusiForce is a request to the online API that will not fail\n",
    "    # if any exception is thrown, we set the scores to -1\n",
    "    if \"fusiForce\" in addOpt:\n",
    "        scores[\"fusiForce\"] = forceWrapper(sendFusiRequest, trimSeqs(seqs, -24, 6))\n",
    "\n",
    "    return scores\n",
    "\n",
    "def printScoreTabSep(seqs, doAll=False):\n",
    "    \" return tab-sep rows with all seqs \"\n",
    "    scoreDict = calcAllScores(seqs, doAll=doAll)\n",
    "    scoreNames = scoreDict.keys()\n",
    "    headers = [\"fullSeq\", \"guideSeq\"]\n",
    "    headers.extend(scoreNames)\n",
    "\n",
    "    print \"\\t\".join(headers)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        row = [seq, seq[30:53]]\n",
    "        for scoreName in scoreNames:\n",
    "            row.append(str(scoreDict[scoreName][i]))\n",
    "        print \"\\t\".join(row)\n",
    "\n",
    "def test():\n",
    "    #sendFusiRequest([ \"GGGAGGCTGCTTTACCCGCTGTGGGGGCGC\", \"GGGAGGCTGCTTTACCCGCTGTGGGGGCGC\"])\n",
    "    #sys.exit(1)\n",
    "    #global binDir\n",
    "    import doctest\n",
    "    doctest.testmod()\n",
    "\n",
    "def parseArgs():\n",
    "    parser = optparse.OptionParser(\"usage: %prog [options] filename - given a file with 100mer sequences +- 50bp around the PAM site, calculate many efficiency scores and output as a tab-sep file to stdout\")\n",
    "    parser.add_option(\"-d\", \"--debug\", dest=\"debug\", action=\"store_true\", help=\"show debug messages\") \n",
    "    parser.add_option(\"-t\", \"--test\", dest=\"test\", action=\"store_true\", help=\"run tests\")\n",
    "    parser.add_option(\"-a\", \"--all\", dest=\"all\", action=\"store_true\", help=\"show all possible scores, even those that are slow to obtain or redundant with others\")\n",
    "    #parser.add_option(\"\", \"--test\", dest=\"test\", action=\"store_true\", help=\"do something\") \n",
    "    (options, args) = parser.parse_args()\n",
    "    if options.debug:\n",
    "        logging.basicConfig(level=logging.DEBUG)\n",
    "    else:\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "    if args==[] and not options.test:\n",
    "        parser.print_help()\n",
    "        exit(1)\n",
    "    return args, options\n",
    "\n",
    "def readSeqs(inFname):\n",
    "    seqs = [line.strip() for line in open(inFname, 'U')]\n",
    "    seqs = [s for s in seqs if len(s)!=0]\n",
    "    filtSeqs = []\n",
    "    for s in seqs:\n",
    "        if len(s) != 100:\n",
    "            logging.error(\"sequence %s is not 100bp long but %d bp long, skipping\" % (s, len(s)))\n",
    "            continue\n",
    "        filtSeqs.append(s)\n",
    "    return filtSeqs\n",
    "\n",
    "# Housden matrix (see function below):\n",
    "# an array of 4x20=80 floats. The first 20 are for A, the next 20 for T, then C, then G\n",
    "# imported from original file received from the authors: matrix_final.txt\n",
    "factors = [\n",
    "    0.4979, 0.7959, 0.7553, 0.6569, 0.9481, 0.7147, 0.437, 0.6212, 0.9077, 1.0, 0.1957, 0.7959, 0.6212, 0.8912, 1.0, 0.5485, 0.9942, 0.5485, 0.455, 1.0, \\\n",
    "    0.6699, 0.5485, 0.275, 0.5972, 0.6212, 0.7555, 1.0, 0.5131, 0.8608, 0.7553, 0.6569, 0.3417, 1.0, 0.016, 0.9146, 0.7555, 0.2906, 0.4979, 0.5485, 0.5131, \n",
    "    0.4979, 0.6869, 0.8528, 0.7643, 0.5325, 0.3417, 0.3417, 0.7643, 0.6434, 0.0092, 0.9331, 0.5325, 0.7272, 0.9708, 0.2905, 0.7272, 0.2957, 0.7918, 0.6434, 0.5062, \\\n",
    "    0.7918, 0.4461, 0.4851, 0.4461, 0.3417, 0.6869, 0.2417, 0.5485, 0.0947, 0.9256, 0.5325, 0.8308, 0.1255, 0.7918, 0.2544, 0.4461, 0.4979, 0.6212, 0.7918, 0.4461\n",
    "]\n",
    "\n",
    "def calcHousden(seqs):\n",
    "    \"\"\"\n",
    "    Calc housden score and round to one decimal point.\n",
    "    Based on java file Crispr.java received from the authors.\n",
    "    >>> calcHousden([\"ATCTGACCTCCCGGCTAATT\"])\n",
    "    [6.9]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for seq in seqs:\n",
    "        seq = seq.upper()\n",
    "        if \"N\" in seq: # cannot do Ns\n",
    "            scores.append(-1.0)\n",
    "            continue\n",
    "\n",
    "        assert(len(seq)==20)\n",
    "        nuclToIndex = {\"A\":0,\"T\":1,\"C\":2,\"G\":3}\n",
    "\n",
    "        score = 1.0\n",
    "        for i in range(0, 20):\n",
    "            nuclIndex = nuclToIndex[seq[i]]\n",
    "            idx = (nuclIndex*20)+i\n",
    "            score *= factors[idx]\n",
    "        score = -1*log10(score)\n",
    "        score = float(\"%0.1f\" % score) # round to one decimal point\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def calcFusiDoench(seqs):\n",
    "    \"\"\"\n",
    "    Input is a 30mer: 4bp 5', 20bp guide, 3bp PAM, 3bp 5'\n",
    "    based on source code sent by John Doench\n",
    "    {'include_strand': False, 'weighted': None, 'num_thread_per_proc': None, 'extra pairs': False, 'gc_features': True, 'test_genes': array([u'CD5', u'CD45', u'THY1', u'H2-K', u'CD28', u'CD43', 'CD33', 'CD13',\n",
    "       'CD15', u'HPRT1', u'CCDC101', u'MED12', u'TADA2B', u'TADA1',\n",
    "       u'CUL3', u'NF1', u'NF2'], dtype=object), 'testing_non_binary_target_name': 'ranks', 'train_genes': array([u'CD5', u'CD45', u'THY1', u'H2-K', u'CD28', u'CD43', 'CD33', 'CD13',\n",
    "       'CD15', u'HPRT1', u'CCDC101', u'MED12', u'TADA2B', u'TADA1',\n",
    "       u'CUL3', u'NF1', u'NF2'], dtype=object), 'cv': 'gene', 'adaboost_alpha': 0.5, 'all pairs': False, 'binary target name': 'score_drug_gene_threshold', 'normalize_features': False, 'nuc_features': True, 'include_gene_effect': False, 'num_genes_remove_train': None, 'include_gene_guide_feature': 0, 'include_known_pairs': False, 'include_gene_feature': False, 'training_metric': 'spearmanr', 'num_proc': 8, 'include_drug': False, 'include_microhomology': False, 'V': 3, 'include_Tm': True, 'adaboost_loss': 'ls', 'rank-transformed target name': 'score_drug_gene_rank', 'include_pi_nuc_feat': True, 'include_sgRNAscore': False, 'flipV1target': False, 'include_NGGX_interaction': True, 'seed': 1, 'NDGC_k': 10, 'raw target name': None, 'all_genes': array([u'CD5', u'CD45', u'THY1', u'H2-K', u'CD28', u'CD43', 'CD33', 'CD13',\n",
    "       'CD15', u'HPRT1', u'CCDC101', u'MED12', u'TADA2B', u'TADA1',\n",
    "       u'CUL3', u'NF1', u'NF2'], dtype=object), 'order': 2, 'include_gene_position': False}\n",
    "    \"\"\"\n",
    "    #aa_cut = 0\n",
    "    #percent_peptide=0\n",
    "    #learn_options[\"V\"] = 2\n",
    "    #model, learn_options = pickle.load(f)\n",
    "    #for seq in seqs:\n",
    "        #get_all_order_nuc_features(seq, feature_sets, learn_options, learn_options[\"order\"], max_index_to_use=30)\n",
    "        #assert(not learn_options[\"gc_features\"])\n",
    "        #assert(not learn_options[\"gene_position\"])\n",
    "    aa_cut = 0\n",
    "    per_peptide=0\n",
    "    f = open(join(fusiDir, 'saved_models/V3_model_nopos.pickle'))\n",
    "    model= pickle.load(f) # if this fails, install sklearn like this: pip install scikit-learn==0.16.1\n",
    "    res = []\n",
    "    for seq in seqs:\n",
    "        pam = seq[25:27]\n",
    "        if pam!=\"GG\":\n",
    "            #res.append(-1)\n",
    "            #continue\n",
    "            seq = list(seq)\n",
    "            seq[25] = \"G\"\n",
    "            seq[26] = \"G\"\n",
    "            seq = \"\".join(seq)\n",
    "        if \"N\" in seq:\n",
    "            res.append(-1)\n",
    "            continue\n",
    "        score = model_comparison.predict(seq, aa_cut, per_peptide, model=model)\n",
    "        res.append(int(round(100*score)))\n",
    "    return res\n",
    "\n",
    "def calcWuCrisprScore(seqs):\n",
    "    \"\"\"\n",
    "    Input is a list of 30mers:\n",
    "    20bp guide, 3bp PAM, 7bp 3' sequence.\n",
    "    >>> calcWuCrisprScore([\"ggtgcagctcgagcaacaggcggc\"])\n",
    "    [93]\n",
    "    \"\"\"\n",
    "\n",
    "    for s in seqs:\n",
    "        assert(len(s)==24)\n",
    "\n",
    "    #tempFh = open(\"temp.fa\", \"w\")\n",
    "    tempFh = tempfile.NamedTemporaryFile()\n",
    "\n",
    "    for s in seqs:\n",
    "        tempFh.write(\">%s\\n%s\\n\" %(s, s))\n",
    "\n",
    "    tempFh.flush()\n",
    "    tmpPath = abspath(tempFh.name)\n",
    "\n",
    "    # the perl script needs cwd to be its dir, so save, change and set back\n",
    "    oldCwd = os.getcwd()\n",
    "    wuCrispDir = getBinPath(\"WU-CRISPR\", isDir=True)\n",
    "    logging.debug(\"Running wu-crisp in %s\" % wuCrispDir)\n",
    "    print(\"Running wu-crisp in %s\" % wuCrispDir)\n",
    "    os.chdir(wuCrispDir)\n",
    "    cmd = \"perl wu-crispr.pl -f %s > /dev/null\" % tmpPath\n",
    "    logging.debug(\"Running %s\" % cmd)\n",
    "    print(\"Running %s\" % cmd)\n",
    "    assert(os.system(cmd)==0)\n",
    "    os.chdir(oldCwd)\n",
    "\n",
    "    #seqId   Score   Sequence        Orientation     Position\n",
    "    #test    87      ggtgcagctcgagcaacagg    sense   1, 31\n",
    "\n",
    "    # I modified the perl script to write to a .outTab file otherwise not\n",
    "    # thread safe\n",
    "    outFname = tempFh.name+\".outTab\"\n",
    "    # but stay compatible with the original perl script\n",
    "    if not isdir(tempFh.name+\".outDir\"):\n",
    "        outFname = join(wuCrispDir, \"WU-CRISPR_V0.9_prediction_result.xls\")\n",
    "        logging.warn(\"The original version of the wu-crispr perl script is used.\")\n",
    "        logging.warn(\"Careful, don't multithread!\")\n",
    "\n",
    "    scoreDict = {}\n",
    "    for line in open(outFname):\n",
    "        if line.startswith(\"seqId\"):\n",
    "            continue\n",
    "        seqId, score, seq, orient, pos = line.split(\"\\t\")\n",
    "        #print \"got wucrisp row\", seqId, score, seq, orient, pos\n",
    "        start = int(pos.split(\",\")[0])-1\n",
    "        if not (start == 0 and orient==\"sense\"):\n",
    "            #print \"skipping, incorrect position\"\n",
    "            continue\n",
    "        #print \"keeping seq/score\", seq, score\n",
    "        scoreDict[seq] = int(score)\n",
    "        #scores.append(int(score))\n",
    "\n",
    "    # return 0 for all sequences where we didn't get a score back from\n",
    "    # wu-crispr\n",
    "    logging.debug(\"got back %d scores, putting in 0 for all others\" % len(scoreDict))\n",
    "    scores = []\n",
    "    guideSeqs = [s[:20].lower() for s in seqs]\n",
    "    #print \"guideseqs\", guideSeqs\n",
    "    #print 'scoreDict', scoreDict\n",
    "    for seq in guideSeqs:\n",
    "        if seq not in scoreDict:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            scores.append(scoreDict[seq])\n",
    "\n",
    "    shutil.rmtree(tempFh.name+\".outDir\")\n",
    "    os.remove(outFname)\n",
    "    return scores\n",
    "\n",
    "# ----------- MAIN --------------\n",
    "if __name__==\"__main__\":\n",
    "    args, options = parseArgs()\n",
    "    if options.test:\n",
    "        test()\n",
    "        sys.exit(0)\n",
    "\n",
    "    #setBinDir(\"../crispor/bin\")\n",
    "    setBinDir(\"./bin\")\n",
    "    inFname = sys.argv[1]\n",
    "    seqs = readSeqs(inFname)\n",
    "    if len(seqs)==0:\n",
    "        logging.error(\"No sequences in input left\")\n",
    "    else:\n",
    "        printScoreTabSep(seqs, options.all)\n",
    "\n",
    "     2020 GitHub, Inc.\n",
    "    Terms\n",
    "    Privacy\n",
    "    Security\n",
    "    Status\n",
    "    Help\n",
    "\n",
    "    Contact GitHub\n",
    "    Pricing\n",
    "    API\n",
    "    Training\n",
    "    Blog\n",
    "    About\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct Barcode\n",
      "TGAAGATCGCGTTCATCAGC   -2.445081\n",
      "TCGCTACCACGTGCCAGTTG   -1.083566\n",
      "TGTCACCTTCAACTTCGACA   -1.715094\n",
      "CTACGGTATTTGCAATATAC   -2.848217\n",
      "GTCTGCGATGAATGTGCCCT   -1.937476\n",
      "AGAACAAGGCGAAGTTCTGG   -2.549638\n",
      "TCCGCTGGTCCCGGTTGCGC   -2.549365\n",
      "CCCGGGACAGGCGACGACGC   -1.903448\n",
      "GTGCTCCTCTTTAGCGCCTC   -1.842970\n",
      "TGCATGGCCTTGTACTGCAT   -2.805005\n",
      "TGTTGCCCACGTAGAGGCGC   -3.099744\n",
      "TACGTGGGCAACATCCCCTT   -2.329987\n",
      "CCAGTTACATCAGTCGTGCC   -2.634432\n",
      "CCTGGCACGACTGATGTAAC   -2.331580\n",
      "TGTGACTGCACTCCGAATAT   -3.126091\n",
      "AGCAGCTATTGACCTATATT   -0.968155\n",
      "TGATTTCATGTGCGATGATG   -2.315172\n",
      "AAGAAGACTTTCTCTTACGC   -2.562462\n",
      "ACTCGAGCTCGACATTCAAA    0.207254\n",
      "CACATCCCCAATGGGGAGTT   -0.962095\n",
      "GTCTTGTCCAAACTCCCCAT   -2.436899\n",
      "GTGTTTGAAGAGACCCAGAT   -1.285940\n",
      "CTCACCTCTCGCCTCCAATC   -1.889177\n",
      "AGGTTGATGTCTCGAACAAG   -1.907186\n",
      "GATGTCGACTCTCTACCGCC   -3.609085\n",
      "TCTATGACCACCAGCCGTTG   -1.061315\n",
      "TCATAGAACCAGTCCAACAC   -2.101546\n",
      "CCAGGGAATCTCATTGACGA   -2.845975\n",
      "CTGCGTGGGGCATGTACTTT   -1.643430\n",
      "AGGAACGGCTTAAGAACCTG   -2.663164\n",
      "                          ...   \n",
      "TATTATTGCCACTGTAGTGA   -3.407241\n",
      "AATAGAGTACTATGCTATGT   -2.590237\n",
      "TCTTCGATTACCTCAAAGCT   -3.881473\n",
      "TGCTTTGTAGAAAAAGTCGC   -2.009883\n",
      "GATGGTGGCCGCAAAGAAGA   -1.584082\n",
      "CTCACTCACCGTCTTCTTTG   -1.588289\n",
      "ACTTTACCTGAAAAGATCTC   -2.124673\n",
      "TCTAACCTAGGTCACTATTG   -2.191489\n",
      "GAACACTTCATCAACCAAAG   -1.219040\n",
      "AAGCAGCTGAGATATAGTAC   -2.931753\n",
      "GCGGGCGATCCAAAGCCCCC   -1.441861\n",
      "GCCGCCGGCTCCCCCGTATG   -2.114146\n",
      "GGCACGAACAAGGACGTGTT   -2.225026\n",
      "CCCAGCGCCGACGGCGACGT   -2.028375\n",
      "TATTATGCAGTCTCATTCCC   -3.774482\n",
      "CAATGTGAATGTCCACATCC   -1.588640\n",
      "AGTAAAGATCCAAGACATCG   -1.801863\n",
      "TGAAGCTGTCCACGATGTCT   -1.270752\n",
      "CTGCTAGGGAGCCCGCGCTC   -1.722820\n",
      "TGACATGTGGGGCATTCGAC   -2.105347\n",
      "CCGGAATTGCATGAACCGCT   -1.670999\n",
      "TCCCAAGTACCTGTTCCGAG   -1.884563\n",
      "GCACCCGCAGCTCCATCCTT   -2.010336\n",
      "GTCACTTACTGCATGGGGCT   -1.594842\n",
      "CAAGTTCGCCGCCAAGGGGG   -1.085953\n",
      "CTCCCCCTTGGCGGCGAACT   -1.440515\n",
      "CCAGACTTTCCAGCGCATCG   -2.411426\n",
      "TCACGTTCTCCACGATGCGC   -2.766727\n",
      "GCTGCCCTCCGAGTCACCGA   -2.307897\n",
      "CATGCCCGGGGGAGTCAATG   -1.860000\n",
      "Length: 1195, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ngene_ls = list(set(df_g['Symbol']))\\nprint gene_ls\\n\\ndf_new = DataFrame()\\n\\nfor gene in gene_ls:\\n    df_gene = df_g[df_g['Symbol']==gene]\\n    #print df_gene\\n    if df_gene.shape[0]>=4:\\n        m = np.mean(df_gene['Score'])\\n        score = [s-m for s in df_gene['Score']]\\n        df_gene['Essential_Zscore'] = score\\n        df_new = pd.concat([df_new,df_gene])\\n    \\nprint df_new\\n\\n#df2 = pd.read_csv('Testing_Bertomeu2018.csv')\\n#df['Essential_Zscore'] = [-i for i in df['Essential_Zscore']]\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "df_g = pd.read_csv('Testing_Sanjana2014-GeCKOv2_update.csv')\n",
    "df_ht = pd.read_csv('GeCKO_HT29.csv',index_col=0)\n",
    "\n",
    "sg_ls = [i[0:20] for i in df_g['sgRNASeq']]\n",
    "\n",
    "score_ls = df_ht.loc[sg_ls,:].iloc[:,4:6].mean(axis=1)\n",
    "print score_ls\n",
    "df_g['Essential_Zscore'] = list(score_ls)\n",
    "\n",
    "'''\n",
    "gene_ls = list(set(df_g['Symbol']))\n",
    "print gene_ls\n",
    "\n",
    "df_new = DataFrame()\n",
    "\n",
    "for gene in gene_ls:\n",
    "    df_gene = df_g[df_g['Symbol']==gene]\n",
    "    #print df_gene\n",
    "    if df_gene.shape[0]>=4:\n",
    "        m = np.mean(df_gene['Score'])\n",
    "        score = [s-m for s in df_gene['Score']]\n",
    "        df_gene['Essential_Zscore'] = score\n",
    "        df_new = pd.concat([df_new,df_gene])\n",
    "    \n",
    "print df_new\n",
    "\n",
    "#df2 = pd.read_csv('Testing_Bertomeu2018.csv')\n",
    "#df['Essential_Zscore'] = [-i for i in df['Essential_Zscore']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_g.to_csv('Testing_Sanjana2014-GeCKOv2_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
